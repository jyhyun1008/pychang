
`2023-06-10`

디노이즈(1)은 [이쪽](https://yeojibur.in/seodangcat/?p=diary/%EB%94%94%EB%85%B8%EC%9D%B4%EC%A6%88)

# 지난 해결책(3)의 결과

<iframe width="560" height="315" class="youtube" src="https://www.youtube.com/embed/47ldaqVOoLc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

이런 느낌이 되었습니다. 이정도도 많이 줄었다고 느껴졌는데요, librosa 페이지를 돌아다니다가 이런 것을 발견했습니다.

# 해결책(4)

This function returns a complex-valued matrix `D` such that

* `np.abs(D[..., f, t])` is the magnitude of frequency bin `f` at frame `t`, and

* `np.angle(D[..., f, t])` is the phase of frequency bin `f` at frame `t`.

요는, `np.real()`과 `np.imag()` 를 쓰지 말고 `np.abs()`와 `np.angle()`을 썼으면 됐다는 겁니다. 그래서 당장 플롯해보았는데요,

![image](https://github.com/jyhyun1008/seodangcat/assets/93899740/be2bbfb4-84d3-4b5d-a6dc-395cb194a85b)

*네?*

저거, 노이즈야? 아니면 랜덤 값?

찾아보니, STFT의 angle값은 원래 저렇다고 하더라구요. 그런데 저게 또 랜덤 값도 아니래요.

일단 저는 저상태에서 한번 결과를 뽑아보기로 했습니다. 결과 데이터의 윗부분에는 결과 `np.angle(y)` 배열을 붙이구요, 입력 데이터의 윗부분에는 노이즈 `tf.random.uniform()` 를 넣어서 pix2pix가 아니라 기존 GAN 방법으로 `np.angle()` 배열과 유사한 값을 생성했어요.

그리고 그 결과는...

<iframe width="560" height="315" class="youtube" src="https://www.youtube.com/embed/TQ3a6gFseZ8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

참담했습니다. 이거말고도 `np.angle()` 값을 랜덤하게 생성해보기도 했는데 그 결과도 유사하게 참담했습니다. 그래서 이건 안된다고 생각하고 있던 찰나, 또 새로운 것을 발견했습니다(이번에는 한국어 웹사이트들을 돌다가 발견했어요.)

# 해결책(5)

> Griffin-Lim !!!

`librosa.griffinlim` 이라는 방법은 STFT의 크기값, 즉 `np.abs()` 값만 가지고도 위상, 즉 `np.angle()`값을 보정하여 원본 오디오 소스를 복원해 줍니다. 저는 이걸 당장 써보기로 했어요!

![image](https://github.com/jyhyun1008/seodangcat/assets/93899740/ec4a8bb3-f104-4cb8-bb19-41321f4a6b95)

정말 리얼이니 이미지너리니 앵글이니 모든 걸 다 빼고, 딱 `np.abs()` 값만 가지고 Pix2Pix 를 수행하고, 그 결과를 Griffin-Lim 방법을 통해 복원 해 주었습니다.

그런데, 똑같이 망한거예요. 찌그러지는 소리가 나고 그러길래, 원본 소스에 대고도 해봤어요. 그러자 똑같이 찌그러지는 소리가 났습니다.

저는 이때까지만 해도 이게 Griffin-Lim의 한계인 줄 알았어요. 그런데 그게 아니었습니다. 전처리를 아예하지않은 찐 원본 소스에서는 찌그러지는 소리가 안 나는 거였어요!

문제는 이랬습니다. 제가 원활환 딥러닝을 위해 STFT 배열에서 1 넘어가는 값들을 다 클리핑해줬는데 그게 문제였던 거였습니다. 알고보니 STFT 결과 배열은 높게는 40까지도 뛰더라구요.

그래서 이번에는 원본 소스의 STFT 배열을 대충 피크의 평균값이었던 20에서 컷해주었고, 20으로 나누어서 데이터를 [0, 1]로 정리해준 후, 그래프의 컬러축을 로그 스케일로 변환해서 어느 정도 학습이 진행되었는지 보기로 했습니다.

![image](https://github.com/jyhyun1008/seodangcat/assets/93899740/f919a322-9e40-4132-bdcb-0e912bbad92f)

간단하게 15분 정도만 학습을 진행하니 여기까지 오더라구요. 기뻤습니다. 지금까지의 방법은 학습에만 1-2시간 정도가 소요되었거든요.

아무튼 이 결과로 후보정을 진행한 뒤, 다시 Griffin-Lim 방법을 사용해보았습니다.

<iframe width="560" height="315" class="youtube" src="https://www.youtube.com/embed/_U9keorshCs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

![image](https://github.com/jyhyun1008/seodangcat/assets/93899740/108cd3d0-e4b4-4aa4-a967-1a521d34e867)

**대박**

그냥 사람이 녹음한 것 같아요.

여전히 좀 먹먹하다고 느낄 수 있는데, 이것은 원본 데이터의 한계 + 학습을 15분만 진행한 점이 크게 작용했다고 생각을 합니다.

아무튼 서당고양이의 디노이즈는 이쯤에서 마치게 될 것 같아요!

수고하셨습니다! 그동안 코드는 하나도 안 썼는데... 코드 포함된 수정 버전을 나중에 벨로그에 업로드해 볼 예정이에요!
